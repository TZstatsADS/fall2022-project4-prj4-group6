{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Machine Learning Fairness Algorithms Evaluation\n",
    "\n",
    "Group 6: \n",
    "* Huang, Xilin (xh2508@columbia.edu)\n",
    "* Nguyen, Kieu-Giang (kn2521@columbia.edu) \n",
    "* Spade, Gabriel (gms2221@columbia.edu) \n",
    "* Wang, Yayuan (yw3548@columbia.edu)\n",
    "* Xu, Jiapeng (jx2427@columbia.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "​​In this project, we are comparing two methodologies introduced by [A2-Maximizing accuracy under fairness constraints (C-SVM and C-LR)](https://arxiv.org/abs/1507.05259) and [A7-Information Theoretic Measures for Fairness-aware Feature selection (FFS)](https://arxiv.org/abs/2106.00772) to obtain a better understanding of the trade-off between accuracy and fairness. The criterion we use to quantify fairness is calibration, meaning that the prediction accuracy of the protected group ought to be equal to the accuracy of the unprotected group. \n",
    "\n",
    "We examine all the algorithms on [COMPAS Dataset](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis) to evaluate their performance. COMPAS dataset contains criminal history and demographic information. In this case, the race of each individual is our protected/sensitive attribute (African-American=0, Caucasian = 1). The binary target label (y) we are interested in is whether the individual was arrested for a crime within 2 years of release. \n",
    "\n",
    "\n",
    "In summary, according to the *A7-Information Theoretic Measures for Fairness-aware Feature Selection*, we select and encode our variables as follows: \n",
    "\n",
    "- Binary class label (y): <code>two_year_recid</code>, indicating whether the individual was arrested for a crime within 2 years of release\n",
    "- Binary sensitive attribute: <code>race</code>, African-American=0, Caucasian = 1\n",
    "- Other features: \n",
    "    *  <code>sex</code>: female = 0, male = 1\n",
    "    *  <code>age</code>: less than 25 = 0, age 25~45 = 1, age older than 45 = 2\n",
    "    *  <code>c_charge_degree</code>: misdemeanor = 0, felony = 1\n",
    "    *  <code>priors_count</code>: none = 0, 1~3 times = 1, more than 3 = 2\n",
    "    *  <code>length_of_stay</code>: normalized time elapsed from in jail until out of jail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "### 2.1 Data Cleansing and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import copy\n",
    "import math\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('./data/compas-scores-two-years.csv')    # load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>6.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid              race     sex  age c_charge_degree  \\\n",
       "1               1  African-American    Male   34               F   \n",
       "2               1  African-American    Male   24               F   \n",
       "6               1         Caucasian    Male   41               F   \n",
       "8               0         Caucasian  Female   39               M   \n",
       "9               1         Caucasian    Male   21               F   \n",
       "\n",
       "   priors_count  length_of_stay  \n",
       "1             0       10.041667  \n",
       "2             4        1.083333  \n",
       "6            14        6.291667  \n",
       "8             0        2.916667  \n",
       "9             1        0.958333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_stay = pd.to_datetime(df_raw[\"c_jail_out\"]) - pd.to_datetime(df_raw[\"c_jail_in\"])    # calculate length of stay (days)\n",
    "df = df_raw\n",
    "df[\"length_of_stay\"] = length_of_stay.astype('timedelta64[h]')/24\n",
    "df = df[[\"two_year_recid\",\"race\",\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]]   # select features we are interested in\n",
    "df = df.dropna()         # drop NA\n",
    "df = df.loc[(df[\"length_of_stay\"] > 0) &                                         # length of stay should be positive\n",
    "       ((df[\"race\"]== \"African-American\") | (df[\"race\"]== \"Caucasian\"))]         # individuals who are African american or Caucasian\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  race  sex  age  c_charge_degree  priors_count  \\\n",
       "1               1     0    1    1                1             0   \n",
       "2               1     0    1    0                1             2   \n",
       "6               1     1    1    1                1             2   \n",
       "8               0     1    0    1                0             0   \n",
       "9               1     1    1    0                1             1   \n",
       "\n",
       "  length_of_stay  \n",
       "1              1  \n",
       "2              0  \n",
       "6              0  \n",
       "8              0  \n",
       "9              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode features\n",
    "df['race'] = df['race'].apply(lambda race: 0 if race == 'African-American' else 1)\n",
    "df['sex'] = df['sex'].apply(lambda sex: 0 if sex == 'Female' else 1)\n",
    "df['age'] = df['age'].apply(lambda age: 0 if age < 25 else (2 if age > 45 else 1))\n",
    "df['c_charge_degree'] = df['c_charge_degree'].apply(lambda c_charge_degree: 0 if c_charge_degree == 'M' else 1)\n",
    "df['priors_count'] = df['priors_count'].apply(lambda priors_count: 0 if priors_count == 0 else (2 if priors_count > 3 else 1))\n",
    "df['length_of_stay'] = pd.cut(df['length_of_stay'], bins = [0, 7, 90, np.inf], labels = [0, 1, 2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=1)      # shuffled the dataset\n",
    "i = int(len(df_shuffled) * 0.7)         # use 70% as training set\n",
    "train = df_shuffled[:i]                 # training set\n",
    "test = df_shuffled[i:]                  # test set\n",
    "\n",
    "label = \"two_year_recid\"\n",
    "sensitive = \"race\"\n",
    "features = [\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, race_train = train[features], train[label].to_numpy(), train[sensitive]\n",
    "x_test, y_test, race_test = test[features], test[label].to_numpy(), test[sensitive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline (Without Constraints)\n",
    "### 3.1 Logistic Regression\n",
    "\n",
    "Before fitting the logistic regression, let’s first define the function to calculate calibration(%) which could be understood as accuracy difference between two race groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for calculating calibration\n",
    "def MyCalibration(sensitive_attr, y_pred, y_true):\n",
    "    cau_index = np.where(sensitive_attr == 1)[0]           # index for Caucasians\n",
    "    african_index = np.where(sensitive_attr == 0)[0]       # index for African-Americans\n",
    "    \n",
    "    y_pred_cau = y_pred[cau_index]           # Caucasians\n",
    "    y_true_cau = y_true[cau_index] \n",
    "    Acc_cau = sum(y_pred_cau == y_true_cau)/len(y_pred_cau)\n",
    "\n",
    "    y_pred_african = y_pred[african_index]   # African-Americans\n",
    "    y_true_african = y_true[african_index]\n",
    "    Acc_african = sum(y_pred_african == y_true_african)/len(y_pred_african)\n",
    "\n",
    "    calibration = (Acc_cau - Acc_african)*100\n",
    "    return(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(random_state = 0).fit(x_train, y_train)   # logistic regression without constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.357483</td>\n",
       "      <td>-0.379807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.672515</td>\n",
       "      <td>0.716337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)\n",
       "0      LR  Train     66.357483       -0.379807\n",
       "1      LR   Test     65.672515        0.716337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_logReg = {\"Methods\": [\"LR\", \"LR\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [logReg.score(x_train, y_train)*100, logReg.score(x_test, y_test)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_train, logReg.predict(x_train), y_train),\n",
    "                                 MyCalibration(race_test, logReg.predict(x_test), y_test)]}\n",
    "\n",
    "pd.DataFrame(summary_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "svm_model = svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>65.981449</td>\n",
       "      <td>0.565399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>0.923580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)\n",
       "0     SVM  Train     65.981449        0.565399\n",
       "1     SVM   Test     65.847953        0.923580"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_svm = {\"Methods\": [\"SVM\", \"SVM\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [svm_model.score(x_train, y_train)*100, svm_model.score(x_test, y_test)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_train, svm_model.predict(x_train), y_train),\n",
    "                                 MyCalibration(race_test, svm_model.predict(x_test), y_test)]}\n",
    "\n",
    "pd.DataFrame(summary_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation of Method 1 (A2)\n",
    "### 4.1 Logistic Regression With Fairness Constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support Vector Machine (SVM) With Fairness Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementation of Method 2 (A7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values_in_arrays(arr):\n",
    "    \n",
    "    # arr: n * m matrix\n",
    "    # each elements in unique_vals contains unique values of ith column in arr\n",
    "\n",
    "    unique_vals = []\n",
    "    for i in range(arr.shape[1]):\n",
    "        unique_vals.append(np.unique(arr[:, i]).tolist())\n",
    "    return unique_vals\n",
    "\n",
    "def power_set(seq):\n",
    "    \n",
    "    #This function create a generator that contains all subsets of seq\n",
    "    \n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else: \n",
    "        for i in power_set(seq[1:]):\n",
    "            yield [seq[0]] + i\n",
    "            yield i\n",
    "            \n",
    "def unique_info(array_1, array_2):\n",
    "    assert array_1.shape[0] == array_2.shape[0]\n",
    "    \n",
    "    n_rows = array_1.shape[0]\n",
    "    n_col_array_1 = array_1.shape[1]\n",
    "    \n",
    "    concated_array = np.concatenate((array_1, array_2), axis=1)\n",
    "    unique_array = unique_values_in_arrays(concated_array)\n",
    "    cartesian_product = list(itertools.product(*unique_array))\n",
    "    \n",
    "    # IQ(T; R1|R2) = ∑t,r1,r2 QT ,R1,R2 (t, r1, r2) log((QT |R1,R2 (t|r1,r2))/ (QT |R2 (t|r2))) \n",
    "    \n",
    "    IQ = 0\n",
    "    for i in cartesian_product:\n",
    "        r1_r2 = len(np.where((concated_array == i).all(axis=1))[0]) / n_rows\n",
    "        r1 = len(np.where((array_1 == i[:n_col_array_1]).all(axis=1))[0]) / n_rows\n",
    "        r2 = len(np.where((array_2 == i[n_col_array_1:]).all(axis=1))[0]) / n_rows\n",
    "        \n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0:\n",
    "            IQ_iter = 0\n",
    "        else:\n",
    "            IQ_iter = r1_r2 * np.log(r1_r2 / r1) / r1\n",
    "        IQ += np.abs(IQ_iter)\n",
    "    return IQ\n",
    "\n",
    "def unique_info_conditional(array_1, array_2, conditional):\n",
    "    assert (array_1.shape[0] == array_2.shape[0]) and (array_1.shape[0] == conditional.shape[0])\n",
    "    \n",
    "    n_rows = array_1.shape[0]\n",
    "    n_col_array_1 = array_1.shape[1]\n",
    "    n_col_array_2 = array_2.shape[1]\n",
    "    \n",
    "    concated_array_2_conditional = np.concatenate((array_2, conditional), axis=1)\n",
    "    concated_array_all           = np.concatenate((array_1, concated_array_2_conditional), axis=1)\n",
    "    unique_array                 = unique_values_in_arrays(concated_array_all)\n",
    "    cartesian_product = list(itertools.product(*unique_array))\n",
    "    \n",
    "    IQ = 0\n",
    "    for i in cartesian_product:\n",
    "        r1_r2 = len(np.where((concated_array_all == i).all(axis=1))[0]) / n_rows\n",
    "        r1    = len(np.where((array_1 == i[:n_col_array_1]).all(axis=1))[0]) / n_rows\n",
    "        r2    = len(np.where((concated_array_all[:, n_col_array_1: -n_col_array_2] == i[n_col_array_1: -n_col_array_2]).all(axis=1))[0]) / n_rows\n",
    "        \n",
    "        try:\n",
    "            r1_given_r2 = len(np.where((concated_array_all[:, :n_col_array_1] == i[ :n_col_array_1]).all(axis=1) & (concated_array_all[:, -n_col_array_2:] == i[-n_col_array_2:]).all(axis=1))[0]) / len(np.where((concated_array_all[:, -n_col_array_2:] == i[-n_col_array_2:]).all(axis=1))[0])\n",
    "        except ZeroDivisionError:\n",
    "            r1_given_r2 = 0\n",
    "        \n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0 or r1_given_r2 == 0:\n",
    "            IQ_iter = 0\n",
    "        else:\n",
    "            IQ_iter = r1_r2 * np.log(r1_r2 / r2) / r1_given_r2\n",
    "        IQ += np.abs(IQ_iter)\n",
    "    return IQ\n",
    "\n",
    "def accuracy_coef(y, x_s, x_s_c, A):\n",
    "    # Calculate accuracy coefficient\n",
    "    conditional = np.concatenate((x_s_c, A), axis=1)\n",
    "    return unique_info_conditional(y, x_s, conditional)\n",
    "\n",
    "def discrimination_coef(y, x_s, A):\n",
    "    # Calculate discrimination coefficient\n",
    "    x_s_a = np.concatenate((x_s, A), axis=1)\n",
    "    return unique_info(y, x_s_a) * unique_info(x_s, A) * unique_info_conditional(x_s, A, y)\n",
    "\n",
    "def marginal_accuracy_coef(y_train, x_train, A, set_tracker):\n",
    "    \n",
    "    #compute  marginal accuracy coefficient\n",
    "    \n",
    "    n_features = x_train.shape[1]\n",
    "    feature_idx = list(range(n_features))\n",
    "    feature_idx.pop(set_tracker)\n",
    "    power_set_features = [x for x in power_set(feature_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley_value =0\n",
    "    for sc_idx in power_set_features:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.copy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            idx_xsc_ui = list(set(list(range(n_features))).difference(set(idx_xs_ui))) # compliment of x_s\n",
    "            vTU = accuracy_coef(y_train.reshape(-1, 1), x_train[:, idx_xs_ui], x_train[:, idx_xsc_ui], A.reshape(-1, 1))\n",
    "\n",
    "             # Compute v(T)\n",
    "            idx_xsc = list(range(n_features))\n",
    "            idx_xsc.pop(set_tracker)\n",
    "            idx_xsc = list(set(idx_xsc).difference(set(sc_idx)))\n",
    "            vT = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], x_train[:, idx_xsc], A.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value\n",
    "\n",
    "def marginal_discrimination_coef(y_train, x_train, A, set_tracker):\n",
    "    \n",
    "    # compute marginal discrimination coefficient\n",
    "    \n",
    "    n_features = x_train.shape[1]\n",
    "    feature_idx = list(range(n_features))\n",
    "    feature_idx.pop(set_tracker)\n",
    "    power_set_features = [x for x in power_set(feature_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley_value =0\n",
    "    for sc_idx in power_set_features:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.copy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            vTU = discrimination_coef(y_train.reshape(-1, 1), x_train[:, idx_xs_ui], A.reshape(-1, 1))\n",
    "\n",
    "            # Compute v(T)\n",
    "            vT = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], A.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.3 s\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination\n",
       "0             Sex  0.999906    37894.189102\n",
       "1             Age  1.202882    47850.121441\n",
       "2   Charge Degree  1.069162    38978.545863\n",
       "3    Priors Count  1.231735    48379.871765\n",
       "4  Length of Stay  1.139896    46926.923113"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "shapley_acc = []\n",
    "shapley_disc = []\n",
    "for i in range(5):\n",
    "    acc_i = marginal_accuracy_coef(y_train, x_train.to_numpy(), race_train.to_numpy(), i)\n",
    "    disc_i = marginal_discrimination_coef(y_train, x_train.to_numpy(), race_train.to_numpy(), i)\n",
    "    \n",
    "    \n",
    "    shapley_acc.append(acc_i)\n",
    "    shapley_disc.append(disc_i)\n",
    "\n",
    "# DataFrame to compare shapely values\n",
    "feature_names = [\"Sex\",\"Age\",\"Charge Degree\",\"Priors Count\",\"Length of Stay\"]\n",
    "shapley_df = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc)),\n",
    "                          columns=[\"Feature\", \"Accuracy\",'Discrimination'])\n",
    "shapley_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** \\\n",
    "According to the algorithm in *'Information Theoretic Measures for Fairness-aware Feature selection (FFS)'*, we calculated the marginal accuracy coefficient and the marginal discrimination coefficient. The result above shows that **Age** and **Priors Counts** have the most significant impact on accuracy and strongest proxies for discrimination simultaneously, which is aligned with the conclusion in the paper A7. Therefore, simply dropping **Age** or **Priors Counts** may highly influence the model accuracy and calibration at the same time.\n",
    "\n",
    "To make a wiser decision for feature selection, we calculated two fairness utility score introduced by the paper A7 under two different hyperparameter $\\alpha$ which trade-off between accuracy and discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_utility_score(Accuracy, Discrimination, alpha):\n",
    "    scores = []\n",
    "    for i in range(5):\n",
    "        score = Accuracy[i] - alpha * Discrimination[i]\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) $\\alpha$ = 0.000001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "      <th>F_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "      <td>0.962012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "      <td>1.155032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "      <td>1.030184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "      <td>1.183355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "      <td>1.092969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination   F_score\n",
       "0             Sex  0.999906    37894.189102  0.962012\n",
       "1             Age  1.202882    47850.121441  1.155032\n",
       "2   Charge Degree  1.069162    38978.545863  1.030184\n",
       "3    Priors Count  1.231735    48379.871765  1.183355\n",
       "4  Length of Stay  1.139896    46926.923113  1.092969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1 = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc, fairness_utility_score(shapley_df['Accuracy'], shapley_df['Discrimination'], 0.000001))),\n",
    "                       columns=[\"Feature\", \"Accuracy\",'Discrimination', 'F_score'])\n",
    "alpha_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) $\\alpha$ = 0.0001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "      <th>F_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "      <td>-2.789513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "      <td>-3.582130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "      <td>-2.828692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "      <td>-3.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "      <td>-3.552796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination   F_score\n",
       "0             Sex  0.999906    37894.189102 -2.789513\n",
       "1             Age  1.202882    47850.121441 -3.582130\n",
       "2   Charge Degree  1.069162    38978.545863 -2.828692\n",
       "3    Priors Count  1.231735    48379.871765 -3.606252\n",
       "4  Length of Stay  1.139896    46926.923113 -3.552796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_2 = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc, fairness_utility_score(shapley_df['Accuracy'], shapley_df['Discrimination'], 0.0001))),\n",
    "                       columns=[\"Feature\", \"Accuracy\",'Discrimination', 'F_score'])\n",
    "alpha_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\\\n",
    "Normally, we would like to remove the feature with the lowest fairness-utility score. Under the circumstances with different $\\alpha$, the featues with the lowest fairness-utility score are:\n",
    "\n",
    "1) When  𝛼=0.000001, **Sex**;\\\n",
    "2) When  𝛼=0.0001, **Priors Count**;\n",
    "\n",
    "A smaller $\\alpha$ means we care more about the accuracy, and A bigger $\\alpha$ means we care more about the discrimination effect. Therefore,  if we care about maintaining very high accuracy, we can choose to remove **Sex**; If we want to minimize the discrimination effect, we can choose to remove **Prior Counts**.\n",
    "\n",
    "In the next step, we will first fit the dataset with the whole five features on our baseline models, and then remove one feature from **Gender**, **Length of Stay**, **Age**, and **Prior Counts** respectively and compare their accuracy and calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression After Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>65.672515</td>\n",
       "      <td>0.716337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>65.906433</td>\n",
       "      <td>1.074866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>62.280702</td>\n",
       "      <td>4.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>65.614035</td>\n",
       "      <td>0.565051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>59.122807</td>\n",
       "      <td>4.241342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.575435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
       "0                None     65.672515         0.716337\n",
       "1                 Sex     65.906433         1.074866\n",
       "2                 Age     62.280702         4.025879\n",
       "3       Charge Degree     65.614035         0.565051\n",
       "4        Priors Count     59.122807         4.241342\n",
       "5      Length of Stay     66.666667         0.575435"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_lr = []\n",
    "Calibration_lr = []\n",
    "\n",
    "for i in ['None'] + features:\n",
    "    if i == 'None':\n",
    "        logReg = LogisticRegression(random_state = 0).fit(x_train, y_train)\n",
    "        Accuracy_lr.append(logReg.score(x_test, y_test)*100)\n",
    "        Calibration_lr.append(MyCalibration(race_test, logReg.predict(x_test), y_test))\n",
    "    else:\n",
    "        x_train_subset = x_train.drop([i],axis = 1)\n",
    "        x_test_subset = x_test.drop([i],axis = 1)\n",
    "        logReg = LogisticRegression(random_state = 0).fit(x_train_subset, y_train)\n",
    "        Accuracy_lr.append(logReg.score(x_test_subset, y_test)*100)\n",
    "        Calibration_lr.append(MyCalibration(race_test, logReg.predict(x_test_subset), y_test))\n",
    "        \n",
    "col_names = ['None'] + feature_names\n",
    "Conclusion_lr = pd.DataFrame(list(zip(col_names, Accuracy_lr, Calibration_lr)),\n",
    "                          columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "Conclusion_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Support Vector Machine (SVM) After Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>0.923580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>66.491228</td>\n",
       "      <td>1.108036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>59.532164</td>\n",
       "      <td>4.313884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>66.140351</td>\n",
       "      <td>-0.046294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>59.122807</td>\n",
       "      <td>4.241342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>63.859649</td>\n",
       "      <td>-0.274305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
       "0                None     65.847953         0.923580\n",
       "1                 Sex     66.491228         1.108036\n",
       "2                 Age     59.532164         4.313884\n",
       "3       Charge Degree     66.140351        -0.046294\n",
       "4        Priors Count     59.122807         4.241342\n",
       "5      Length of Stay     63.859649        -0.274305"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_svm = []\n",
    "Calibration_svm = []\n",
    "\n",
    "for i in ['None'] + features:\n",
    "    if i == 'None':\n",
    "        svm_model = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "        svm_model = svm_model.fit(x_train, y_train)\n",
    "        Accuracy_svm.append(svm_model.score(x_test, y_test)*100)\n",
    "        Calibration_svm.append(MyCalibration(race_test, svm_model.predict(x_test), y_test))\n",
    "    else:\n",
    "        x_train_subset = x_train.drop([i],axis = 1)\n",
    "        x_test_subset = x_test.drop([i],axis = 1)\n",
    "        svm_model = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "        svm_model = svm_model.fit(x_train_subset, y_train)\n",
    "        Accuracy_svm.append(svm_model.score(x_test_subset, y_test)*100)\n",
    "        Calibration_svm.append(MyCalibration(race_test, svm_model.predict(x_test_subset), y_test))\n",
    "        \n",
    "Conclusion_svm = pd.DataFrame(list(zip(col_names, Accuracy_svm, Calibration_svm)),\n",
    "                              columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "Conclusion_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\\\n",
    "According to the marginal accuracy coefficient and the marginal discrimination coefficient, we expect the model accuracy and calibration will decrease simultaneously after dropping **Age** and **Priors Count**. However, the fact is the model accuracy did decrease in both models but the calibration increased in contrast, which is not aligned with the theory. From the table above, the best model of linear regression is the model without the feature '**Length of Stay**' and the best model of support vector machine is the model without the feature '**Charge Degree**' when we take accuracy and discrimination effects into account at the same time. It shows a pretty high accuracy with the lowest calibration.\n",
    "\n",
    "There are several possible explanations for the fluctuation of the calibration:\n",
    "\n",
    "1) Fairness-utility scores are pretty close to each other under our several choices of hyperparameters, so that we cannot guarantee removing the feature with the lowest score is always better than removing another feature also with a very low score.\n",
    "\n",
    "2) The marginal accuracy coefficient and marginal discrimination coefficient of the five features are on the same scale. There are no features with outlying discrimination scores or accuracy scores. Therefore we didn't observe remarkable differences under our evaluation metrics.\n",
    "\n",
    "3) Number of test data, and the proportion of train/test/validation may matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- length_of_stay\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5 features, but LogisticRegression is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# summary table for test results\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ------please add test set results to the following table-------\u001b[39;00m\n\u001b[0;32m      5\u001b[0m summary_total \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethods\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m----> 6\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mlogReg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, svm_model\u001b[38;5;241m.\u001b[39mscore(x_test, y_test)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m      7\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalibration(\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m: [MyCalibration(race_test, logReg\u001b[38;5;241m.\u001b[39mpredict(x_test), y_test),\n\u001b[0;32m      8\u001b[0m                                  MyCalibration(race_test, svm_model\u001b[38;5;241m.\u001b[39mpredict(x_test), y_test)]}\n\u001b[0;32m      9\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(summary_total)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\linear_model\\_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    449\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\linear_model\\_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    427\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\eods-s22\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 5 features, but LogisticRegression is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "# summary table for test results\n",
    "\n",
    "# ------please add test set results to the following table-------\n",
    "\n",
    "summary_total = {\"Methods\": [\"LR\", \"SVM\"], \n",
    "              \"Accuracy (%)\": [logReg.score(x_test, y_test)*100, svm_model.score(x_test, y_test)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_test, logReg.predict(x_test), y_test),\n",
    "                                 MyCalibration(race_test, svm_model.predict(x_test), y_test)]}\n",
    "pd.DataFrame(summary_total)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s22",
   "language": "python",
   "name": "eods-s22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebd061f7599129e24578b6f2998b2d2c640c780fe891a51fdef921dba6069598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
