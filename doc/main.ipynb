{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Machine Learning Fairness Algorithms Evaluation\n",
    "\n",
    "Group 6: \n",
    "* Huang, Xilin (xh2508@columbia.edu)\n",
    "* Nguyen, Kieu-Giang (kn2521@columbia.edu) \n",
    "* Spade, Gabriel (gms2221@columbia.edu) \n",
    "* Wang, Yayuan (yw3548@columbia.edu)\n",
    "* Xu, Jiapeng (jx2427@columbia.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "​​In this project, we are comparing two methodologies introduced by [A2-Maximizing accuracy under fairness constraints (C-SVM and C-LR)](https://arxiv.org/abs/1507.05259) and [A7-Information Theoretic Measures for Fairness-aware Feature selection (FFS)](https://arxiv.org/abs/2106.00772) to obtain a better understanding of the trade-off between accuracy and fairness. The criterion we use to quantify fairness is calibration, meaning that the prediction accuracy of the protected group ought to be equal to the accuracy of the unprotected group. \n",
    "\n",
    "We examine all the algorithms on [COMPAS Dataset](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis) to evaluate their performance. COMPAS dataset contains criminal history and demographic information. In this case, the race of each individual is our protected/sensitive attribute (African-American=0, Caucasian = 1). The binary target label (y) we are interested in is whether the individual was arrested for a crime within 2 years of release. \n",
    "\n",
    "\n",
    "In summary, according to the *A7-Information Theoretic Measures for Fairness-aware Feature Selection*, we select and encode our variables as follows: \n",
    "\n",
    "- Binary class label (y): <code>two_year_recid</code>, indicating whether the individual was arrested for a crime within 2 years of release\n",
    "- Binary sensitive attribute: <code>race</code>, African-American=0, Caucasian = 1\n",
    "- Other features: \n",
    "    *  <code>sex</code>: female = 0, male = 1\n",
    "    *  <code>age</code>: less than 25 = 0, age 25~45 = 1, age older than 45 = 2\n",
    "    *  <code>c_charge_degree</code>: misdemeanor = 0, felony = 1\n",
    "    *  <code>priors_count</code>: none = 0, 1~3 times = 1, more than 3 = 2\n",
    "    *  <code>length_of_stay</code>: normalized time elapsed from in jail until out of jail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "### 2.1 Data Cleansing and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import copy\n",
    "import math\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../data/compas-scores-two-years.csv')    # load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>6.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid              race     sex  age c_charge_degree  \\\n",
       "1               1  African-American    Male   34               F   \n",
       "2               1  African-American    Male   24               F   \n",
       "6               1         Caucasian    Male   41               F   \n",
       "8               0         Caucasian  Female   39               M   \n",
       "9               1         Caucasian    Male   21               F   \n",
       "\n",
       "   priors_count  length_of_stay  \n",
       "1             0       10.041667  \n",
       "2             4        1.083333  \n",
       "6            14        6.291667  \n",
       "8             0        2.916667  \n",
       "9             1        0.958333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_stay = pd.to_datetime(df_raw[\"c_jail_out\"]) - pd.to_datetime(df_raw[\"c_jail_in\"])    # calculate length of stay (days)\n",
    "df = df_raw\n",
    "df[\"length_of_stay\"] = length_of_stay.astype('timedelta64[h]')/24\n",
    "df = df[[\"two_year_recid\",\"race\",\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]]   # select features we are interested in\n",
    "df = df.dropna()         # drop NA\n",
    "df = df.loc[(df[\"length_of_stay\"] > 0) &                                         # length of stay should be positive\n",
    "       ((df[\"race\"]== \"African-American\") | (df[\"race\"]== \"Caucasian\"))]         # individuals who are African american or Caucasian\n",
    "df1 = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.187151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.356541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.321875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.358905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   two_year_recid  race  sex  age  c_charge_degree  priors_count  \\\n",
       "1               1     0    1    1                1             0   \n",
       "2               1     0    1    0                1             2   \n",
       "6               1     1    1    1                1             2   \n",
       "8               0     1    0    1                0             0   \n",
       "9               1     1    1    0                1             1   \n",
       "\n",
       "   length_of_stay  \n",
       "1       -0.187151  \n",
       "2       -0.356541  \n",
       "6       -0.258059  \n",
       "8       -0.321875  \n",
       "9       -0.358905  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode features\n",
    "df['race'] = df['race'].apply(lambda race: 0 if race == 'African-American' else 1)\n",
    "df['sex'] = df['sex'].apply(lambda sex: 0 if sex == 'Female' else 1)\n",
    "df['age'] = df['age'].apply(lambda age: 0 if age < 25 else (2 if age > 45 else 1))\n",
    "df['c_charge_degree'] = df['c_charge_degree'].apply(lambda c_charge_degree: 0 if c_charge_degree == 'M' else 1)\n",
    "df['priors_count'] = df['priors_count'].apply(lambda priors_count: 0 if priors_count == 0 else (2 if priors_count > 3 else 1))\n",
    "#df['length_of_stay'] = pd.cut(df['length_of_stay'], bins = [0, 7, 90, np.inf], labels = [0, 1, 2])\n",
    "df['length_of_stay'] = (df['length_of_stay'] - df['length_of_stay'].mean())/df['length_of_stay'].std()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=1)      # shuffled the dataset\n",
    "i = int(len(df_shuffled) * 0.7)         # use 70% as training set\n",
    "train = df_shuffled[:i]                 # training set\n",
    "test = df_shuffled[i:]                  # test set\n",
    "\n",
    "label = \"two_year_recid\"\n",
    "sensitive = \"race\"\n",
    "features = [\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, race_train = train[features], train[label].to_numpy(), train[sensitive]\n",
    "x_test, y_test, race_test = test[features], test[label].to_numpy(), test[sensitive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline (Without Constraints)\n",
    "### 3.1 Logistic Regression\n",
    "\n",
    "Before fitting the logistic regression, let’s first define the function to calculate calibration(%) which could be understood as accuracy difference between two race groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for calculating calibration\n",
    "def MyCalibration(sensitive_attr, y_pred, y_true):\n",
    "    cau_index = np.where(sensitive_attr == 1)[0]           # index for Caucasians\n",
    "    african_index = np.where(sensitive_attr == 0)[0]       # index for African-Americans\n",
    "    \n",
    "    y_pred_cau = y_pred[cau_index]           # Caucasians\n",
    "    y_true_cau = y_true[cau_index] \n",
    "    Acc_cau = sum(y_pred_cau == y_true_cau)/len(y_pred_cau)\n",
    "\n",
    "    y_pred_african = y_pred[african_index]   # African-Americans\n",
    "    y_true_african = y_true[african_index]\n",
    "    Acc_african = sum(y_pred_african == y_true_african)/len(y_pred_african)\n",
    "\n",
    "    calibration = (Acc_cau - Acc_african)*100\n",
    "    return(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg1 = LogisticRegression(random_state = 0).fit(x_train, y_train)   # logistic regression without constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.307345</td>\n",
       "      <td>0.016413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>66.257310</td>\n",
       "      <td>0.502892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)\n",
       "0      LR  Train     66.307345        0.016413\n",
       "1      LR   Test     66.257310        0.502892"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_logReg = {\"Methods\": [\"LR\", \"LR\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [logReg1.score(x_train, y_train)*100, logReg1.score(x_test, y_test)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_train, logReg1.predict(x_train), y_train),\n",
    "                                 MyCalibration(race_test, logReg1.predict(x_test), y_test)]}\n",
    "\n",
    "pd.DataFrame(summary_logReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1 = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "svm_model1 = svm_model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>66.006518</td>\n",
       "      <td>0.731009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>64.561404</td>\n",
       "      <td>-0.431792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods    Set  Accuracy (%)  Calibration(%)\n",
       "0     SVM  Train     66.006518        0.731009\n",
       "1     SVM   Test     64.561404       -0.431792"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_svm = {\"Methods\": [\"SVM\", \"SVM\"], \n",
    "              \"Set\": [\"Train\", \"Test\"],\n",
    "              \"Accuracy (%)\": [svm_model1.score(x_train, y_train)*100, svm_model1.score(x_test, y_test)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_train, svm_model1.predict(x_train), y_train),\n",
    "                                 MyCalibration(race_test, svm_model1.predict(x_test), y_test)]}\n",
    "\n",
    "pd.DataFrame(summary_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation of Method 1 (A2)\n",
    "### 4.1 Logistic Regression With Fairness Constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../lib/')\n",
    "import loss_function as lf\n",
    "import clr as clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logistic loss function to compute the loss\n",
    "loss_function = lf.logistic_loss\n",
    "\n",
    "# Set max_iter = -1 to take as many iterations as we want\n",
    "max_iter = -1\n",
    "\n",
    "# Set apply_fairness_constraints to be true\n",
    "apply_fairness_constraints = 1 \n",
    "\n",
    "# Sensitive attributes\n",
    "sensitive_attrs = ['race']\n",
    "\n",
    "# Covariance threshold\n",
    "sensitive_attrs_to_cov_thresh = {'race': 0}\n",
    "\n",
    "x_control_train = {'race': race_train}\n",
    "x_control_test = {'race': race_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLR = clr.LR()\n",
    "w = CLR.train_model(x_train, y_train, x_control_train, loss_function, max_iter, apply_fairness_constraints, sensitive_attrs, sensitive_attrs_to_cov_thresh)\n",
    "clr_predict_y_train = np.sign(np.dot(x_train,w))\n",
    "clr_predict_y_test = np.sign(np.dot(x_test,w))\n",
    "clr_train_accuracy = sum(clr_predict_y_train == y_train)/len(y_train)\n",
    "clr_test_accuracy = sum(clr_predict_y_test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Train</td>\n",
       "      <td>47.630985</td>\n",
       "      <td>-13.727658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.076023</td>\n",
       "      <td>-10.153752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  Calibration (%)\n",
       "0       C-LR  Train     47.630985       -13.727658\n",
       "1       C-LR   Test     47.076023       -10.153752"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_clr = {\"Classifier\": [\"C-LR\", \"C-LR\"],\n",
    "               \"Set\": [\"Train\", \"Test\"],\n",
    "               \"Accuracy (%)\": [clr_train_accuracy*100, clr_test_accuracy*100],\n",
    "               \"Calibration (%)\": [MyCalibration(race_train, clr_predict_y_train, y_train), MyCalibration(race_test, clr_predict_y_test, y_test)]}\n",
    "pd.DataFrame(summary_clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support Vector Machine (SVM) With Fairness Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csvm as csvm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hinge loss function to compute the loss\n",
    "loss_function = lf.hinge_loss\n",
    "\n",
    "# Penalty\n",
    "C = 1\n",
    "\n",
    "# Lambda\n",
    "lamb = 1\n",
    "# Number of epochs\n",
    "epochs = 1000\n",
    "# Learning rate \n",
    "lr = 0.1  \n",
    "\n",
    "# Gamma value strongly affect the accuracy, higher gamma will cause a huge decrease in accuracy\n",
    "# To ensure our accuracy, we need to set it at a low value. In this case, we set gamma = 0\n",
    "gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running custom model\n"
     ]
    }
   ],
   "source": [
    "CSVM = csvm.SVM()\n",
    "w = CSVM.train_model(x_train, y_train, x_control_train, loss_function, C, max_iter, lamb, epochs, lr, apply_fairness_constraints, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma=0)\n",
    "csvm_predict_y_train = np.sign(np.dot(x_train, w))\n",
    "csvm_predict_y_test = np.sign(np.dot(x_test, w))\n",
    "csvm_train_accuracy = sum(csvm_predict_y_train == y_train)/len(y_train)\n",
    "csvm_test_accuracy = sum(csvm_predict_y_test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Train</td>\n",
       "      <td>48.032088</td>\n",
       "      <td>-13.779814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>47.777778</td>\n",
       "      <td>-9.571395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Set  Accuracy (%)  Calibration (%)\n",
       "0      C-SVM  Train     48.032088       -13.779814\n",
       "1      C-SVM   Test     47.777778        -9.571395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_c_svm = {\"Classifier\": [\"C-SVM\", \"C-SVM\"],\n",
    "                \"Set\": [\"Train\", \"Test\"],\n",
    "                \"Accuracy (%)\": [csvm_train_accuracy*100, csvm_test_accuracy*100],\n",
    "                \"Calibration (%)\": [MyCalibration(race_train, csvm_predict_y_train, y_train), MyCalibration(race_test, csvm_predict_y_test, y_test)]}\n",
    "pd.DataFrame(summary_c_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementation of Method 2 (A7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode features as proposed by A7\n",
    "df1 = df_raw\n",
    "df1[\"length_of_stay\"] = length_of_stay.astype('timedelta64[h]')/24\n",
    "df1 = df1[[\"two_year_recid\",\"race\",\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]]   # select features we are interested in\n",
    "df1 = df1.dropna()         # drop NA\n",
    "df1 = df1.loc[(df1[\"length_of_stay\"] > 0) &                                         # length of stay should be positive\n",
    "       ((df1[\"race\"]== \"African-American\") | (df1[\"race\"]== \"Caucasian\"))]         # individuals who are African american or Caucasian\n",
    "\n",
    "\n",
    "df1['race'] = df1['race'].apply(lambda race: 0 if race == 'African-American' else 1)\n",
    "df1['sex'] = df1['sex'].apply(lambda sex: 0 if sex == 'Female' else 1)\n",
    "df1['age'] = df1['age'].apply(lambda age: 0 if age < 25 else (2 if age > 45 else 1))\n",
    "df1['c_charge_degree'] = df1['c_charge_degree'].apply(lambda c_charge_degree: 0 if c_charge_degree == 'M' else 1)\n",
    "df1['priors_count'] = df1['priors_count'].apply(lambda priors_count: 0 if priors_count == 0 else (2 if priors_count > 3 else 1))\n",
    "df1['length_of_stay'] = pd.cut(df1['length_of_stay'], bins = [0, 7, 90, np.inf], labels = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled1 = df1.sample(frac=1, random_state=1)      # shuffled the dataset\n",
    "i = int(len(df_shuffled1) * 0.7)         # use 70% as training set\n",
    "train1 = df_shuffled1[:i]                 # training set\n",
    "test1 = df_shuffled1[i:]                  # test set\n",
    "\n",
    "label = \"two_year_recid\"\n",
    "sensitive = \"race\"\n",
    "features = [\"sex\",\"age\",\"c_charge_degree\",\"priors_count\",\"length_of_stay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, y_train1, race_train1 = train1[features], train1[label].to_numpy(), train1[sensitive]\n",
    "x_test1, y_test1, race_test1 = test1[features], test1[label].to_numpy(), test1[sensitive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values_in_arrays(arr):\n",
    "    \n",
    "    # arr: n * m matrix\n",
    "    # each elements in unique_vals contains unique values of ith column in arr\n",
    "\n",
    "    unique_vals = []\n",
    "    for i in range(arr.shape[1]):\n",
    "        unique_vals.append(np.unique(arr[:, i]).tolist())\n",
    "    return unique_vals\n",
    "\n",
    "def power_set(seq):\n",
    "    \n",
    "    #This function create a generator that contains all subsets of seq\n",
    "    \n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else: \n",
    "        for i in power_set(seq[1:]):\n",
    "            yield [seq[0]] + i\n",
    "            yield i\n",
    "            \n",
    "def unique_info(array_1, array_2):\n",
    "    assert array_1.shape[0] == array_2.shape[0]\n",
    "    \n",
    "    n_rows = array_1.shape[0]\n",
    "    n_col_array_1 = array_1.shape[1]\n",
    "    \n",
    "    concated_array = np.concatenate((array_1, array_2), axis=1)\n",
    "    unique_array = unique_values_in_arrays(concated_array)\n",
    "    cartesian_product = list(itertools.product(*unique_array))\n",
    "    \n",
    "    # IQ(T; R1|R2) = ∑t,r1,r2 QT ,R1,R2 (t, r1, r2) log((QT |R1,R2 (t|r1,r2))/ (QT |R2 (t|r2))) \n",
    "    \n",
    "    IQ = 0\n",
    "    for i in cartesian_product:\n",
    "        r1_r2 = len(np.where((concated_array == i).all(axis=1))[0]) / n_rows\n",
    "        r1 = len(np.where((array_1 == i[:n_col_array_1]).all(axis=1))[0]) / n_rows\n",
    "        r2 = len(np.where((array_2 == i[n_col_array_1:]).all(axis=1))[0]) / n_rows\n",
    "        \n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0:\n",
    "            IQ_iter = 0\n",
    "        else:\n",
    "            IQ_iter = r1_r2 * np.log(r1_r2 / r1) / r1\n",
    "        IQ += np.abs(IQ_iter)\n",
    "    return IQ\n",
    "\n",
    "def unique_info_conditional(array_1, array_2, conditional):\n",
    "    assert (array_1.shape[0] == array_2.shape[0]) and (array_1.shape[0] == conditional.shape[0])\n",
    "    \n",
    "    n_rows = array_1.shape[0]\n",
    "    n_col_array_1 = array_1.shape[1]\n",
    "    n_col_array_2 = array_2.shape[1]\n",
    "    \n",
    "    concated_array_2_conditional = np.concatenate((array_2, conditional), axis=1)\n",
    "    concated_array_all           = np.concatenate((array_1, concated_array_2_conditional), axis=1)\n",
    "    unique_array                 = unique_values_in_arrays(concated_array_all)\n",
    "    cartesian_product = list(itertools.product(*unique_array))\n",
    "    \n",
    "    IQ = 0\n",
    "    for i in cartesian_product:\n",
    "        r1_r2 = len(np.where((concated_array_all == i).all(axis=1))[0]) / n_rows\n",
    "        r1    = len(np.where((array_1 == i[:n_col_array_1]).all(axis=1))[0]) / n_rows\n",
    "        r2    = len(np.where((concated_array_all[:, n_col_array_1: -n_col_array_2] == i[n_col_array_1: -n_col_array_2]).all(axis=1))[0]) / n_rows\n",
    "        \n",
    "        try:\n",
    "            r1_given_r2 = len(np.where((concated_array_all[:, :n_col_array_1] == i[ :n_col_array_1]).all(axis=1) & (concated_array_all[:, -n_col_array_2:] == i[-n_col_array_2:]).all(axis=1))[0]) / len(np.where((concated_array_all[:, -n_col_array_2:] == i[-n_col_array_2:]).all(axis=1))[0])\n",
    "        except ZeroDivisionError:\n",
    "            r1_given_r2 = 0\n",
    "        \n",
    "        if r1_r2 == 0 or r1 == 0 or r2 == 0 or r1_given_r2 == 0:\n",
    "            IQ_iter = 0\n",
    "        else:\n",
    "            IQ_iter = r1_r2 * np.log(r1_r2 / r2) / r1_given_r2\n",
    "        IQ += np.abs(IQ_iter)\n",
    "    return IQ\n",
    "\n",
    "def accuracy_coef(y, x_s, x_s_c, A):\n",
    "    # Calculate accuracy coefficient\n",
    "    conditional = np.concatenate((x_s_c, A), axis=1)\n",
    "    return unique_info_conditional(y, x_s, conditional)\n",
    "\n",
    "def discrimination_coef(y, x_s, A):\n",
    "    # Calculate discrimination coefficient\n",
    "    x_s_a = np.concatenate((x_s, A), axis=1)\n",
    "    return unique_info(y, x_s_a) * unique_info(x_s, A) * unique_info_conditional(x_s, A, y)\n",
    "\n",
    "def marginal_accuracy_coef(y_train, x_train, A, set_tracker):\n",
    "    \n",
    "    #compute  marginal accuracy coefficient\n",
    "    \n",
    "    n_features = x_train.shape[1]\n",
    "    feature_idx = list(range(n_features))\n",
    "    feature_idx.pop(set_tracker)\n",
    "    power_set_features = [x for x in power_set(feature_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley_value =0\n",
    "    for sc_idx in power_set_features:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.copy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            idx_xsc_ui = list(set(list(range(n_features))).difference(set(idx_xs_ui))) # compliment of x_s\n",
    "            vTU = accuracy_coef(y_train.reshape(-1, 1), x_train[:, idx_xs_ui], x_train[:, idx_xsc_ui], A.reshape(-1, 1))\n",
    "\n",
    "             # Compute v(T)\n",
    "            idx_xsc = list(range(n_features))\n",
    "            idx_xsc.pop(set_tracker)\n",
    "            idx_xsc = list(set(idx_xsc).difference(set(sc_idx)))\n",
    "            vT = accuracy_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], x_train[:, idx_xsc], A.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value\n",
    "\n",
    "def marginal_discrimination_coef(y_train, x_train, A, set_tracker):\n",
    "    \n",
    "    # compute marginal discrimination coefficient\n",
    "    \n",
    "    n_features = x_train.shape[1]\n",
    "    feature_idx = list(range(n_features))\n",
    "    feature_idx.pop(set_tracker)\n",
    "    power_set_features = [x for x in power_set(feature_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley_value =0\n",
    "    for sc_idx in power_set_features:\n",
    "            coef = math.factorial(len(sc_idx)) * math.factorial(n_features - len(sc_idx) - 1) / math.factorial(n_features)\n",
    "\n",
    "            # Compute v(T ∪ {i}) \n",
    "            idx_xs_ui = copy.copy(sc_idx) # create copy of subset list\n",
    "            idx_xs_ui.append(set_tracker) # append feature index\n",
    "            vTU = discrimination_coef(y_train.reshape(-1, 1), x_train[:, idx_xs_ui], A.reshape(-1, 1))\n",
    "\n",
    "            # Compute v(T)\n",
    "            vT = discrimination_coef(y_train.reshape(-1, 1), x_train[:, sc_idx], A.reshape(-1, 1))\n",
    "\n",
    "            marginal = vTU - vT\n",
    "            shapley_value = shapley_value + coef * marginal\n",
    "    return shapley_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 176 ms, total: 16 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination\n",
       "0             Sex  0.999906    37894.189102\n",
       "1             Age  1.202882    47850.121441\n",
       "2   Charge Degree  1.069162    38978.545863\n",
       "3    Priors Count  1.231735    48379.871765\n",
       "4  Length of Stay  1.139896    46926.923113"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "shapley_acc = []\n",
    "shapley_disc = []\n",
    "for i in range(5):\n",
    "    acc_i = marginal_accuracy_coef(y_train1, x_train1.to_numpy(), race_train1.to_numpy(), i)\n",
    "    disc_i = marginal_discrimination_coef(y_train1, x_train1.to_numpy(), race_train1.to_numpy(), i)\n",
    "    \n",
    "    \n",
    "    shapley_acc.append(acc_i)\n",
    "    shapley_disc.append(disc_i)\n",
    "\n",
    "# DataFrame to compare shapely values\n",
    "feature_names = [\"Sex\",\"Age\",\"Charge Degree\",\"Priors Count\",\"Length of Stay\"]\n",
    "shapley_df = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc)),\n",
    "                          columns=[\"Feature\", \"Accuracy\",'Discrimination'])\n",
    "shapley_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** \\\n",
    "According to the algorithm in *'Information Theoretic Measures for Fairness-aware Feature selection (FFS)'*, we calculated the marginal accuracy coefficient and the marginal discrimination coefficient. The result above shows that **Age** and **Priors Counts** have the most significant impact on accuracy and strongest proxies for discrimination simultaneously, which is aligned with the conclusion in the paper A7. Therefore, simply dropping **Age** or **Priors Counts** may highly influence the model accuracy and calibration at the same time.\n",
    "\n",
    "To make a wiser decision for feature selection, we calculated two fairness utility score introduced by the paper A7 under two different hyperparameter $\\alpha$ which trade-off between accuracy and discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_utility_score(Accuracy, Discrimination, alpha):\n",
    "    scores = []\n",
    "    for i in range(5):\n",
    "        score = Accuracy[i] - alpha * Discrimination[i]\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) $\\alpha$ = 0.000001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "      <th>F_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "      <td>0.962012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "      <td>1.155032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "      <td>1.030184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "      <td>1.183355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "      <td>1.092969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination   F_score\n",
       "0             Sex  0.999906    37894.189102  0.962012\n",
       "1             Age  1.202882    47850.121441  1.155032\n",
       "2   Charge Degree  1.069162    38978.545863  1.030184\n",
       "3    Priors Count  1.231735    48379.871765  1.183355\n",
       "4  Length of Stay  1.139896    46926.923113  1.092969"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1 = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc, fairness_utility_score(shapley_df['Accuracy'], shapley_df['Discrimination'], 0.000001))),\n",
    "                       columns=[\"Feature\", \"Accuracy\",'Discrimination', 'F_score'])\n",
    "alpha_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) $\\alpha$ = 0.0001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Discrimination</th>\n",
       "      <th>F_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>37894.189102</td>\n",
       "      <td>-2.789513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>47850.121441</td>\n",
       "      <td>-3.582130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>38978.545863</td>\n",
       "      <td>-2.828692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>1.231735</td>\n",
       "      <td>48379.871765</td>\n",
       "      <td>-3.606252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.139896</td>\n",
       "      <td>46926.923113</td>\n",
       "      <td>-3.552796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Accuracy  Discrimination   F_score\n",
       "0             Sex  0.999906    37894.189102 -2.789513\n",
       "1             Age  1.202882    47850.121441 -3.582130\n",
       "2   Charge Degree  1.069162    38978.545863 -2.828692\n",
       "3    Priors Count  1.231735    48379.871765 -3.606252\n",
       "4  Length of Stay  1.139896    46926.923113 -3.552796"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_2 = pd.DataFrame(list(zip(feature_names, shapley_acc, shapley_disc, fairness_utility_score(shapley_df['Accuracy'], shapley_df['Discrimination'], 0.0001))),\n",
    "                       columns=[\"Feature\", \"Accuracy\",'Discrimination', 'F_score'])\n",
    "alpha_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\\\n",
    "Normally, we would like to remove the feature with the lowest fairness-utility score. Under the circumstances with different $\\alpha$, the featues with the lowest fairness-utility score are:\n",
    "\n",
    "1) When  𝛼=0.000001, **Sex**;\\\n",
    "2) When  𝛼=0.0001, **Priors Count**;\n",
    "\n",
    "A smaller $\\alpha$ means we care more about the accuracy, and A bigger $\\alpha$ means we care more about the discrimination effect. Therefore,  if we care about maintaining very high accuracy, we can choose to remove **Sex**; If we want to minimize the discrimination effect, we can choose to remove **Prior Counts**.\n",
    "\n",
    "In the next step, we will first fit the dataset with the whole five features on our baseline models, and then remove one feature from **Gender**, **Length of Stay**, **Age**, and **Prior Counts** respectively and compare their accuracy and calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression After Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>65.672515</td>\n",
       "      <td>0.716337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>65.906433</td>\n",
       "      <td>1.074866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>62.280702</td>\n",
       "      <td>4.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>65.614035</td>\n",
       "      <td>0.565051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>59.122807</td>\n",
       "      <td>4.241342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.575435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
       "0                None     65.672515         0.716337\n",
       "1                 Sex     65.906433         1.074866\n",
       "2                 Age     62.280702         4.025879\n",
       "3       Charge Degree     65.614035         0.565051\n",
       "4        Priors Count     59.122807         4.241342\n",
       "5      Length of Stay     66.666667         0.575435"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_lr = []\n",
    "Calibration_lr = []\n",
    "\n",
    "for i in ['None'] + features:\n",
    "    if i == 'None':\n",
    "        logReg = LogisticRegression(random_state = 0).fit(x_train1, y_train1)\n",
    "        Accuracy_lr.append(logReg.score(x_test1, y_test1)*100)\n",
    "        Calibration_lr.append(MyCalibration(race_test1, logReg.predict(x_test1), y_test1))\n",
    "    else:\n",
    "        x_train_subset = x_train1.drop([i],axis = 1)\n",
    "        x_test_subset = x_test1.drop([i],axis = 1)\n",
    "        logReg = LogisticRegression(random_state = 0).fit(x_train_subset, y_train1)\n",
    "        Accuracy_lr.append(logReg.score(x_test_subset, y_test1)*100)\n",
    "        Calibration_lr.append(MyCalibration(race_test1, logReg.predict(x_test_subset), y_test1))\n",
    "        \n",
    "col_names = ['None'] + feature_names\n",
    "Conclusion_lr = pd.DataFrame(list(zip(col_names, Accuracy_lr, Calibration_lr)),\n",
    "                          columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "Conclusion_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Support Vector Machine (SVM) After Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>65.847953</td>\n",
       "      <td>0.923580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>66.491228</td>\n",
       "      <td>1.108036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>59.532164</td>\n",
       "      <td>4.313884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>66.140351</td>\n",
       "      <td>-0.046294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priors Count</td>\n",
       "      <td>59.122807</td>\n",
       "      <td>4.241342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>63.859649</td>\n",
       "      <td>-0.274305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy (%)  Calibration (%)\n",
       "0                None     65.847953         0.923580\n",
       "1                 Sex     66.491228         1.108036\n",
       "2                 Age     59.532164         4.313884\n",
       "3       Charge Degree     66.140351        -0.046294\n",
       "4        Priors Count     59.122807         4.241342\n",
       "5      Length of Stay     63.859649        -0.274305"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_svm = []\n",
    "Calibration_svm = []\n",
    "\n",
    "for i in ['None'] + features:\n",
    "    if i == 'None':\n",
    "        svm_model = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "        svm_model = svm_model.fit(x_train1, y_train1)\n",
    "        Accuracy_svm.append(svm_model.score(x_test1, y_test1)*100)\n",
    "        Calibration_svm.append(MyCalibration(race_test1, svm_model.predict(x_test1), y_test1))\n",
    "    else:\n",
    "        x_train_subset = x_train1.drop([i],axis = 1)\n",
    "        x_test_subset = x_test1.drop([i],axis = 1)\n",
    "        svm_model = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "        svm_model = svm_model.fit(x_train_subset, y_train1)\n",
    "        Accuracy_svm.append(svm_model.score(x_test_subset, y_test1)*100)\n",
    "        Calibration_svm.append(MyCalibration(race_test1, svm_model.predict(x_test_subset), y_test1))\n",
    "        \n",
    "Conclusion_svm = pd.DataFrame(list(zip(col_names, Accuracy_svm, Calibration_svm)),\n",
    "                              columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "Conclusion_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\\\n",
    "According to the marginal accuracy coefficient and the marginal discrimination coefficient, we expect the model accuracy and calibration will decrease simultaneously after dropping **Age** and **Priors Count**. However, the fact is the model accuracy did decrease in both models but the calibration increased in contrast, which is not aligned with the theory. From the table above, the best model of linear regression is the model without the feature '**Length of Stay**' and the best model of support vector machine is the model without the feature '**Charge Degree**' when we take accuracy and discrimination effects into account at the same time. It shows a pretty high accuracy with the lowest calibration.\n",
    "\n",
    "There are several possible explanations for the fluctuation of the calibration:\n",
    "\n",
    "1) Fairness-utility scores are pretty close to each other under our several choices of hyperparameters, so that we cannot guarantee removing the feature with the lowest score is always better than removing another feature also with a very low score.\n",
    "\n",
    "2) The marginal accuracy coefficient and marginal discrimination coefficient of the five features are on the same scale. There are no features with outlying discrimination scores or accuracy scores. Therefore we didn't observe remarkable differences under our evaluation metrics.\n",
    "\n",
    "3) Number of test data, and the proportion of train/test/validation may matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression without \"Length of Stay\"\n",
    "\n",
    "x_train_subset2 = x_train1.drop([\"length_of_stay\"],axis = 1)\n",
    "x_test_subset2 = x_test1.drop([\"length_of_stay\"],axis = 1)\n",
    "logReg_selection = LogisticRegression(random_state = 0).fit(x_train_subset2, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression without \"Length of Stay\"\n",
    "\n",
    "x_train_subset3 = x_train1.drop([\"c_charge_degree\"],axis = 1)\n",
    "x_test_subset3 = x_test1.drop([\"c_charge_degree\"],axis = 1)\n",
    "svm_model_selection = SVC(kernel = 'linear', probability = True, random_state = 0)\n",
    "svm_model_selection = svm_model.fit(x_train_subset3, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Calibration(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>66.257310</td>\n",
       "      <td>0.502892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>64.561404</td>\n",
       "      <td>-0.431792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-LR</td>\n",
       "      <td>47.076023</td>\n",
       "      <td>-10.153752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-SVM</td>\n",
       "      <td>47.777778</td>\n",
       "      <td>-9.571395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S-LR</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.575435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S-SVM</td>\n",
       "      <td>66.140351</td>\n",
       "      <td>-0.046294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Methods  Accuracy (%)  Calibration(%)\n",
       "0      LR     66.257310        0.502892\n",
       "1     SVM     64.561404       -0.431792\n",
       "2    C-LR     47.076023      -10.153752\n",
       "3   C-SVM     47.777778       -9.571395\n",
       "4    S-LR     66.666667        0.575435\n",
       "5   S-SVM     66.140351       -0.046294"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary table for test results\n",
    "\n",
    "summary_total = {\"Methods\": [\"LR\", \"SVM\", \"C-LR\", \"C-SVM\", \"S-LR\", \"S-SVM\"], \n",
    "              \"Accuracy (%)\": [logReg1.score(x_test, y_test)*100, svm_model1.score(x_test, y_test)*100,\n",
    "                               clr_test_accuracy*100, csvm_test_accuracy*100,\n",
    "                               logReg_selection.score(x_test_subset2, y_test1)*100,\n",
    "                               svm_model_selection.score(x_test_subset3, y_test1)*100],\n",
    "              \"Calibration(%)\": [MyCalibration(race_test, logReg1.predict(x_test), y_test),\n",
    "                                 MyCalibration(race_test, svm_model1.predict(x_test), y_test),\n",
    "                                 MyCalibration(race_test, clr_predict_y_test, y_test), \n",
    "                                 MyCalibration(race_test, csvm_predict_y_test, y_test),\n",
    "                                 MyCalibration(race_test, logReg_selection.predict(x_test_subset2), y_test1),\n",
    "                                 MyCalibration(race_test, svm_model_selection.predict(x_test_subset3), y_test1)]}\n",
    "pd.DataFrame(summary_total)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between methods proposed by A2 and A7, the feature selection approach does a better job of increasing accuracy and lowering the calibration. In addition, With similar accuracy scores, S-SVM is more promising regarding trade-off accuracy and fairness considerations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebd061f7599129e24578b6f2998b2d2c640c780fe891a51fdef921dba6069598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
